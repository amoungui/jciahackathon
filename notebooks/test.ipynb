{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02189f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Ajouter le répertoire principal du projet au chemin de recherche des modules\n",
    "sys.path.append(os.path.abspath('../'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "from tensorflow.keras.applications import ResNet50 \n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les dimensions de l'image d'entrée (doit correspondre à ce qu'attend ResNet)\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_CHANNELS = 3\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "NUM_CLASSES = 6\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  # Tu peux ajuster le nombre d'epochs\n",
    "LEARNING_RATE = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle ResNet50 pré-entraîné sur ImageNet, sans la couche supérieure (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=INPUT_SHAPE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d788a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geler les couches du modèle de base pour l'entraînement initial\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Ajouter nos propres couches de classification\n",
    "head_model = base_model.output\n",
    "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(256, activation='relu')(head_model)\n",
    "head_model = Dense(NUM_CLASSES, activation='softmax')(head_model)\n",
    "\n",
    "# Créer le modèle final\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et prétraiter tes données (assure-toi de redimensionner les images à 224x224)\n",
    "def load_data(directory, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for dirname in os.listdir(directory):\n",
    "        path = os.path.join(directory, dirname)\n",
    "        if os.path.isdir(path):\n",
    "            for filename in os.listdir(path):\n",
    "                img_path = os.path.join(path, filename)\n",
    "                try:\n",
    "                    image = cv2.imread(img_path)\n",
    "                    if image is not None:\n",
    "                        image = cv2.resize(image, target_size)\n",
    "                        data.append(image)\n",
    "                        labels.append(dirname)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur de chargement de l'image {img_path}: {e}\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cf66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../dataset\"\n",
    "datadir = os.path.join(path, \"african_plums\")\n",
    "data, labels = load_data(datadir)\n",
    "data = data.astype('float32') / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation de données (tu peux l'adapter)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2320184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks (Early Stopping)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle (seulement la tête de classification au début)\n",
    "print(\"[INFO] training head of the network...\")\n",
    "H = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(X_test) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning (facultatif) - Décongeler certaines couches supérieures du modèle de base\n",
    "print(\"[INFO] fine-tuning the last few layers of the network...\")\n",
    "for layer in base_model.layers[-20:]: # Décongeler les 20 dernières couches\n",
    "    layer.trainable = True\n",
    "\n",
    "# Ré-compiler le modèle avec un taux d'apprentissage plus faible pour le fine-tuning\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE / 10)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3706e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuer l'entraînement avec les couches dégelées\n",
    "FINE_TUNE_EPOCHS = EPOCHS // 2 # Entraîner pour moins d'epochs en fine-tuning\n",
    "H_fine_tune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(X_test) // BATCH_SIZE,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluer le modèle final\n",
    "print(\"[INFO] evaluating the network...\")\n",
    "loss, accuracy = model.evaluate(test_generator, steps=len(X_test) // BATCH_SIZE)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer le rapport de classification\n",
    "# type: ignore\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred_probs = model.predict(test_generator, steps=len(X_test) // BATCH_SIZE)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = test_generator.classes\n",
    "class_names = le.classes_\n",
    "\n",
    "print(\"[INFO] generating classification report...\")\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Afficher la matrice de confusion (facultatif)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
